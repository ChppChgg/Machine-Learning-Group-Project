{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11dff997",
   "metadata": {},
   "source": [
    "# UFCFAS-15-2 - Machine learning Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b5f1f0f",
   "metadata": {},
   "source": [
    "## Machine Learning Stock Trading Tool\n",
    "\n",
    "#### - Sam Waxman - 23023667\n",
    "#### - Temi Adeolu-Salako - student number\n",
    "#### - Matt Nogodula - student number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c137391",
   "metadata": {},
   "source": [
    "# Predicting Top 5 Trades for Tomorrow\n",
    "\n",
    "# Stock Market Prediction Using Machine Learning\n",
    "\n",
    "This project uses supervised machine learning models to predict stock market trades as BUY, SELL, or HOLD based on historical stock data and news sentiment. The aim is to assist traders in making informed decisions by analysing patterns across technical indicators and aggregated sentiment data. The machine learning models (Random Forest, XGBoost, Logistic Regression) vote and make their prediction for the user.\n",
    "\n",
    "The top 5 trades are selected based on a combined **confidence score** and **sentiment strength**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245fa347",
   "metadata": {},
   "source": [
    "## 1. Related Work\n",
    "\n",
    "_(To be completed)_\n",
    "\n",
    "Include discussion here of existing trading systems, ML models used in financial predictions, and approaches combining technical indicators and sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c284e",
   "metadata": {},
   "source": [
    "## 2. Preparing Environment\n",
    "\n",
    "In this section, we prepare our environment by importing all the required libraries for data handling, plotting, and model inference. We also load pre-trained machine learning models, data scalers, and encoders which are used throughout the pipeline.\n",
    "\n",
    "These components allow us to process raw financial data and make stock trading predictions based on both technical indicators and sentiment scores.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b4ca0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.12' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# Library imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from datetime import datetime, timedelta\n",
    "from data_prep import download_stock_data, get_sp500_tickers\n",
    "from sentiment_score import get_cached_sentiment\n",
    "from indicators import add_technical_indicators\n",
    "\n",
    "# Load models\n",
    "rf = joblib.load(\"new/models/random_forest_model.pkl\")\n",
    "xgb = joblib.load(\"new/models/xgboost_model.pkl\")\n",
    "lr = joblib.load(\"new/models/logistic_model.pkl\")\n",
    "scaler = joblib.load(\"new/models/scaler.pkl\")\n",
    "label_encoder = joblib.load(\"new/models/label_encoder.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c3548c",
   "metadata": {},
   "source": [
    "## 3. Data Acquisition\n",
    "\n",
    "Here, we fetch historical stock price data using the `yfinance` API and prepare it for further processing. This includes daily Open, High, Low, Close, and Volume (OHLCV) data.\n",
    "\n",
    "Additionally, we use our custom-built sentiment system to retrieve pre-computed sentiment scores from financial news sources. This data will later be merged with technical indicators to enhance prediction performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a166cc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = get_sp500_tickers()\n",
    "data_example = download_stock_data(tickers[0], start=\"2023-01-01\", end=\"2023-12-31\")\n",
    "data_example.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce57565",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "This stage involves calculating a range of technical indicators from the raw stock price data. Indicators such as RSI, MACD, EMA, and OBV are added to give the model quantitative signals based on market momentum and trends.\n",
    "\n",
    "We also integrate sentiment scores as a feature, providing qualitative insight into market psychology. Any rows missing indicator values are removed to maintain data integrity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9571052",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_COLS = [\n",
    "    \"Open\", \"High\", \"Low\", \"Close\", \"Volume\",\n",
    "    \"sentiment_7d_avg\", \"RSI\", \"MACD\", \"MACD_Signal\",\n",
    "    \"SMA\", \"EMA\", \"OBV\", \"Momentum\", \"WilliamsR\"\n",
    "]\n",
    "\n",
    "data_feat = add_technical_indicators(data_example)\n",
    "data_feat[\"sentiment_7d_avg\"] = get_cached_sentiment(tickers[0])\n",
    "data_feat.dropna(subset=FEATURE_COLS[6:], inplace=True)\n",
    "data_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d6b2f2",
   "metadata": {},
   "source": [
    "## 5. Model Training\n",
    "\n",
    "This section shows how models were trained on labeled data using technical and sentiment features. We use Random Forest, XGBoost, and Logistic Regression classifiers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca30a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"new/csv_files/training_data.csv\")\n",
    "X = df[FEATURE_COLS]\n",
    "y = df[\"Label\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss').fit(X_train, y_train)\n",
    "lr = LogisticRegression(max_iter=200).fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest:\\n\", classification_report(y_test, rf.predict(X_test), target_names=le.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ba3372",
   "metadata": {},
   "source": [
    "## 6. Feature Importance\n",
    "\n",
    "Understanding which features most influence model predictions can provide insight into model behaviour and market dynamics. Below we visualise feature importance from the trained Random Forest model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7482d305",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=importances[indices], y=[FEATURE_COLS[i] for i in indices])\n",
    "plt.title(\"Feature Importance - Random Forest\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5189f21",
   "metadata": {},
   "source": [
    "## 7. Prediction & Buy/Sell Signals\n",
    "\n",
    "We define a function that takes a single stock ticker and predicts the most likely trade action for the next day: BUY, SELL, or HOLD.\n",
    "\n",
    "It combines probability outputs from three models—Random Forest, XGBoost, and Logistic Regression—then adjusts the decision based on recent sentiment. This ensemble voting system improves decision robustness and reduces overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4469a8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tomorrow(ticker, portfolio_value=10000):\n",
    "    df = download_stock_data(ticker, start=(datetime.today() - timedelta(days=90)).strftime(\"%Y-%m-%d\"))\n",
    "    if df.empty or len(df) < 10:\n",
    "        return None\n",
    "\n",
    "    df = add_technical_indicators(df)\n",
    "    df.dropna(subset=FEATURE_COLS[6:], inplace=True)\n",
    "    if df.empty:\n",
    "        return None\n",
    "\n",
    "    latest = df.iloc[-1].copy()\n",
    "    try:\n",
    "        sentiment = get_cached_sentiment(ticker)\n",
    "    except:\n",
    "        sentiment = 0.0\n",
    "\n",
    "    latest[\"sentiment_7d_avg\"] = sentiment\n",
    "    X_df = pd.DataFrame([latest[FEATURE_COLS]])\n",
    "    X_scaled = scaler.transform(X_df)\n",
    "\n",
    "    rf_probs = rf.predict_proba(X_scaled)[0]\n",
    "    xgb_probs = xgb.predict_proba(X_scaled)[0]\n",
    "    lr_probs = lr.predict_proba(X_scaled)[0]\n",
    "\n",
    "    labels = label_encoder.classes_\n",
    "    avg_probs = (rf_probs + xgb_probs + lr_probs) / 3\n",
    "    decision_index = avg_probs.argmax()\n",
    "    decision = labels[decision_index]\n",
    "\n",
    "    rf_label = label_encoder.inverse_transform([rf.predict(X_scaled)[0]])[0]\n",
    "    xgb_label = label_encoder.inverse_transform([xgb.predict(X_scaled)[0]])[0]\n",
    "    lr_label = label_encoder.inverse_transform([lr.predict(X_scaled)[0]])[0]\n",
    "    votes = [rf_label, xgb_label, lr_label]\n",
    "\n",
    "    adjusted = decision\n",
    "    if sentiment > 0.6 and decision == \"HOLD\":\n",
    "        adjusted = \"BUY\"\n",
    "    elif sentiment < -0.6 and decision == \"HOLD\":\n",
    "        adjusted = \"SELL\"\n",
    "\n",
    "    return {\n",
    "        \"Ticker\": ticker,\n",
    "        \"Final Decision\": adjusted,\n",
    "        \"Confidence\": round(avg_probs[decision_index], 3),\n",
    "        \"Sentiment\": round(sentiment, 3),\n",
    "        \"Votes\": votes\n",
    "    }\n",
    "\n",
    "predict_tomorrow(\"AAPL\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e6d471",
   "metadata": {},
   "source": [
    "## 8. Model Performance\n",
    "\n",
    "This section evaluates how well each trained model performs in classifying BUY, SELL, and HOLD decisions. We use accuracy, precision, recall, and F1-score as metrics. Confusion matrices are also plotted to visualise how often models confuse the labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17702362",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Random Forest\n",
    "print(\"=== Random Forest ===\")\n",
    "print(classification_report(y_test, rf.predict(X_test), target_names=le.classes_))\n",
    "\n",
    "cm_rf = confusion_matrix(y_test, rf.predict(X_test))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_rf, display_labels=le.classes_).plot(cmap=\"Blues\")\n",
    "plt.title(\"Random Forest - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "print(\"=== XGBoost ===\")\n",
    "print(classification_report(y_test, xgb.predict(X_test), target_names=le.classes_))\n",
    "\n",
    "cm_xgb = confusion_matrix(y_test, xgb.predict(X_test))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_xgb, display_labels=le.classes_).plot(cmap=\"Greens\")\n",
    "plt.title(\"XGBoost - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(classification_report(y_test, lr.predict(X_test), target_names=le.classes_))\n",
    "\n",
    "cm_lr = confusion_matrix(y_test, lr.predict(X_test))\n",
    "ConfusionMatrixDisplay(confusion_matrix=cm_lr, display_labels=le.classes_).plot(cmap=\"Oranges\")\n",
    "plt.title(\"Logistic Regression - Confusion Matrix\")\n",
    "plt.grid(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a5036d",
   "metadata": {},
   "source": [
    "## 9. Backtesting\n",
    "\n",
    "This section simulates how the model’s predictions would have performed historically by applying predicted trades over a specified date range.\n",
    "\n",
    "The goal is to estimate how much a portfolio would gain or lose if it followed the model's recommendations using real past data. We track portfolio value over time, profits/losses per trade, and the number of trades executed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1346b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtest import backtest_ticker\n",
    "df_backtest = backtest_ticker(\"AAPL\")\n",
    "df_backtest[[\"Date\", \"Decision\", \"Profit/Loss (£)\", \"Portfolio Value (£)\"]].tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb86813",
   "metadata": {},
   "source": [
    "## 10. Performance Visualisations\n",
    "\n",
    "We plot the simulated portfolio value across time to visually assess the effectiveness of the trading strategy.\n",
    "\n",
    "These charts help highlight whether the strategy consistently increases value, stagnates, or performs worse than baseline approaches, providing a quick diagnostic of model reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d076d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df_backtest[\"Date\"], df_backtest[\"Portfolio Value (£)\"], label=\"Portfolio Value\", linewidth=2)\n",
    "plt.title(\"Portfolio Value Over Time\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Portfolio (£)\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011f8bbd",
   "metadata": {},
   "source": [
    "## 11. Benchmark Comparisons\n",
    "\n",
    "To determine the true value of our ML-driven trading strategy, we compare it to a basic benchmark: buying the stock once and holding it throughout the same period.\n",
    "\n",
    "This allows us to see if the model is actually providing an edge over traditional long-term investing or if it's simply overfitting or overtrading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e399e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_price = df_backtest.iloc[0][\"Entry Price\"]\n",
    "final_price = df_backtest.iloc[-1][\"Future Price\"]\n",
    "buy_hold_value = 10000 * (final_price / initial_price)\n",
    "\n",
    "print(f\"Buy & Hold Portfolio (£): {round(buy_hold_value, 2)}\")\n",
    "print(f\"ML Strategy Portfolio (£): {round(df_backtest['Portfolio Value (£)'].iloc[-1], 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c53c001",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This project developed a stock trading recommendation system using machine learning, technical analysis, and financial sentiment data. It explored three models (Random Forest, XGBoost, Logistic Regression) and used ensemble voting to improve reliability.\n",
    "\n",
    "Key takeaways:\n",
    "- The model was able to simulate profitable trades in some scenarios.\n",
    "- Sentiment adjustment helped correct HOLD bias in uncertain predictions.\n",
    "- Backtesting gave a realistic view of strategy performance compared to traditional investing.\n",
    "\n",
    "Future improvements could include:\n",
    "- Dealing with class imbalance using oversampling or weighting\n",
    "- Multi-day trade horizon forecasting\n",
    "- Real-time integration with a trading API\n",
    "\n",
    "This system forms a strong foundation for developing data-driven trading strategies.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
